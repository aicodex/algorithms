{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os; os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharTransformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def build_vocab(self, text):\n",
    "        self.vocab = sorted(list(set(text)))\n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def encode_one_hot(self, char):\n",
    "        k = self.vocab.index(char)\n",
    "        arr = np.zeros(self.vocab_size, dtype=np.bool8)\n",
    "        arr[k] = 1\n",
    "        return arr\n",
    "    \n",
    "    def decode_one_hot(self, arr):\n",
    "        idx = np.argmax(arr)\n",
    "        return self.vocab[idx]\n",
    "    \n",
    "    def batch_encode_one_hot(self, text):\n",
    "        return np.array([self.encode_one_hot(c) for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnn_sliding_window_indices(seq_len, time_steps, batch_size, epochs=1):\n",
    "    from collections import deque\n",
    "\n",
    "    i = 0\n",
    "    assert seq_len >= time_steps + batch_size + 2, \"sequence must be larger than time_steps+batch_size+2\"\n",
    "    while True:\n",
    "        if i > seq_len - time_steps - batch_size - 2:\n",
    "            if epochs <= 0:\n",
    "                break\n",
    "            epochs -= 1\n",
    "            i = 0        \n",
    "        batch = []\n",
    "        for j in range(batch_size):\n",
    "            x_start = i + j\n",
    "            x_stop = x_start + time_steps\n",
    "            y_start = x_start + 1\n",
    "            y_stop = x_stop + 1\n",
    "            batch.append((x_start, x_stop, y_start, y_stop))\n",
    "        yield batch\n",
    "        i += 1\n",
    "\n",
    "def rnn_data_gen(seq, time_steps=None, batch_size=None, epochs=None, last_label_only=True):\n",
    "    windows = rnn_sliding_window_indices(seq.shape[0], \n",
    "                                         time_steps=time_steps,\n",
    "                                         batch_size=batch_size,\n",
    "                                         epochs=epochs)\n",
    "    for batch_indices in windows:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for x_start, x_stop, y_start, y_stop in batch_indices:\n",
    "            x_batch.append(seq[x_start:x_stop])\n",
    "            if last_label_only:\n",
    "                y_batch.append(seq[y_stop-1])\n",
    "            else:\n",
    "                y_batch.append(seq[y_start:y_stop])\n",
    "        yield (np.array(x_batch), np.array(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shakespeare\n",
    "import urllib\n",
    "TEXT = urllib.urlopen(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\").read().lower()[:200000]\n",
    "charxform = CharTransformer()\n",
    "charxform.build_vocab(TEXT)\n",
    "x_one_hot = charxform.batch_encode_one_hot(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "TIME_STEPS = 20\n",
    "INPUT_SIZE = charxform.vocab_size\n",
    "OUTPUT_SIZE = INPUT_SIZE\n",
    "NB_SAMPLES = len(TEXT) - TIME_STEPS - BATCH_SIZE - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "199976/199970 [==============================] - 608s - loss: 2.2236 - acc: 0.3774   \n",
      "Epoch 2/20\n",
      "199976/199970 [==============================] - 603s - loss: 1.7727 - acc: 0.4783   \n",
      "Epoch 3/20\n",
      "199976/199970 [==============================] - 588s - loss: 1.6816 - acc: 0.5009   \n",
      "Epoch 4/20\n",
      "199976/199970 [==============================] - 607s - loss: 1.7020 - acc: 0.4939   \n",
      "Epoch 5/20\n",
      "199976/199970 [==============================] - 606s - loss: 1.7452 - acc: 0.4919   \n",
      "Epoch 6/20\n",
      "199976/199970 [==============================] - 605s - loss: 1.7266 - acc: 0.4996   \n",
      "Epoch 7/20\n",
      "199976/199970 [==============================] - 603s - loss: 1.6426 - acc: 0.5158   \n",
      "Epoch 8/20\n",
      "199976/199970 [==============================] - 604s - loss: 1.6476 - acc: 0.5229   \n",
      "Epoch 9/20\n",
      "199976/199970 [==============================] - 603s - loss: 1.9976 - acc: 0.4752   \n",
      "Epoch 10/20\n",
      "199976/199970 [==============================] - 606s - loss: 1.6657 - acc: 0.5141   \n",
      "Epoch 11/20\n",
      "199976/199970 [==============================] - 606s - loss: 1.6172 - acc: 0.5240   \n",
      "Epoch 12/20\n",
      "199976/199970 [==============================] - 611s - loss: 1.6357 - acc: 0.5128   \n",
      "Epoch 13/20\n",
      "199976/199970 [==============================] - 750s - loss: 1.7007 - acc: 0.5065   \n",
      "Epoch 14/20\n",
      "199976/199970 [==============================] - 745s - loss: 1.6841 - acc: 0.5121   \n",
      "Epoch 15/20\n",
      "199976/199970 [==============================] - 659s - loss: 1.6248 - acc: 0.5243   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb37195bcd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "gen = rnn_data_gen(x_one_hot, time_steps=TIME_STEPS, batch_size=BATCH_SIZE, epochs=2000)\n",
    "opt = Adam(lr=.001)\n",
    "early_stop_cb = EarlyStopping(monitor='loss', patience=3, verbose=0, mode='auto')\n",
    "model_ckpt_cb = ModelCheckpoint(\"model.ckpt\", monitor='loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, batch_input_shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), return_sequences=False))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(OUTPUT_SIZE, activation=\"softmax\"))\n",
    "model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(gen, samples_per_epoch=NB_SAMPLES , nb_epoch=20, verbose=1, callbacks=[model_ckpt_cb, early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sample(probs, temperature):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(probs).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def sample_chars(seed, model, max_length=1000, temp=.5):\n",
    "    text = seed\n",
    "    while len(text) < max_length:\n",
    "        x = np.zeros((BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=np.float32)\n",
    "        x[0] = charxform.batch_encode_one_hot(text[-TIME_STEPS:])\n",
    "        probs = model.predict_proba(x, verbose=0)[0]\n",
    "        index = sample(probs, temp)\n",
    "        text += charxform.vocab[index]\n",
    "    print text\n",
    "    \n",
    "\n",
    "# model.load_weights(\"model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h' imprisoned absencresere and the sind of tour the thour the strare thoughtr sore the sared and that mare of wind that the sumere the be and in the to do so to that a do there that of your the with with whing though the of to come be for in to thath to to that i stord be that that math to that be that the sume to that that with the selet that i sond sond the love of that be be the worth of which to that be in thour of thath to so so more o the bure that so so mare the of the sores and on sore to the the streth sure the be the stours and love that i some be thou be the with that that be that in of the for that thoughtred be thour that        55\n",
      "r the nd be shour so fore of the to be of that so sime the of the tort your the sor to the stord of to shat that that be that to that here,\n",
      "  the sure sund to the the with i sore to this at the stort  the be of that that store sond of be though the of ind the stind of to that the of the beand the of thate then be the share to stor bearter with s\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(TEXT) - 20 - 2)\n",
    "end = start+20\n",
    "sample_chars(TEXT[start:end], model, temp=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
